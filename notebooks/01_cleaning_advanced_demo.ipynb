{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddf4fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Import nettoyage\n",
    "from load_data import load_data\n",
    "from cleaning import (\n",
    "    clean_dataframe,\n",
    "    make_default_config,\n",
    "    filter_by_text_quality,\n",
    "    filter_stop_tags,\n",
    "    filter_by_user_density,\n",
    "    add_spatial_density_flag,\n",
    ")\n",
    "\n",
    "print(\"‚úì Imports OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e658c321",
   "metadata": {},
   "source": [
    "## 1. Chargement et nettoyage de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cc3604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger donn√©es brutes\n",
    "df_raw, load_report = load_data('../data/flickr_data2.csv')\n",
    "print(f\"Dataset brut: {len(df_raw):,} lignes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b372202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nettoyage de base (conservatif)\n",
    "config = make_default_config()\n",
    "config.sample_n = 50000  # √âchantillon pour demo rapide\n",
    "\n",
    "df_clean, report = clean_dataframe(df_raw, config)\n",
    "\n",
    "print(f\"\\nDataset nettoy√©: {len(df_clean):,} lignes\")\n",
    "print(f\"Colonnes: {list(df_clean.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15635103",
   "metadata": {},
   "source": [
    "## 2. Statistiques de base\n",
    "\n",
    "Analyse du dataset nettoy√© (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8f8988",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"BASELINE - Dataset nettoy√© conservatif\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nTaille: {len(df_clean):,} photos\")\n",
    "print(f\"GPS valides: {(~df_clean[['lat','lon']].isna().any(axis=1)).sum():,}\")\n",
    "print(f\"Dates valides: {df_clean['has_valid_date'].sum():,}\")\n",
    "print(f\"Texte non-vide: {(df_clean['text_merged'] != '').sum():,}\")\n",
    "print(f\"Tags non-vides: {(df_clean['tags_clean'] != '').sum():,}\")\n",
    "\n",
    "# Utilisateurs\n",
    "print(f\"\\nUtilisateurs uniques: {df_clean['user_id'].nunique():,}\")\n",
    "user_counts = df_clean['user_id'].value_counts()\n",
    "print(f\"Photos par user - m√©diane: {user_counts.median():.0f}\")\n",
    "print(f\"Photos par user - top 3: {user_counts.head(3).to_dict()}\")\n",
    "\n",
    "# Texte\n",
    "word_counts = df_clean['text_merged'].str.split().str.len()\n",
    "print(f\"\\nMots par photo - moyenne: {word_counts.mean():.1f}\")\n",
    "print(f\"Mots par photo - m√©diane: {word_counts.median():.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6ff954",
   "metadata": {},
   "source": [
    "## 3. NIVEAU 1 - Filtrage qualit√© texte\n",
    "\n",
    "**Cas d'usage**: Description s√©mantique des clusters\n",
    "\n",
    "**Justification**: Photos sans tags/titre n'apportent rien au text mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8103d718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er vue \"text_ready\" = photos avec info s√©mantique\n",
    "df_text_ready = filter_by_text_quality(\n",
    "    df_clean,\n",
    "    min_words=3,\n",
    "    require_tags=False\n",
    ")\n",
    "\n",
    "print(f\"\\nR√©sultat:\")\n",
    "print(f\"  Baseline: {len(df_clean):,} photos\")\n",
    "print(f\"  Text-ready: {len(df_text_ready):,} photos\")\n",
    "print(f\"  Perte: {len(df_clean) - len(df_text_ready):,} ({(1 - len(df_text_ready)/len(df_clean))*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nüí° Usage: Garder df_clean pour clustering, df_text_ready pour TF-IDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022a073c",
   "metadata": {},
   "source": [
    "## 4. NIVEAU 1 - Filtrage stop-tags\n",
    "\n",
    "**Cas d'usage**: TF-IDF plus discriminant\n",
    "\n",
    "**Justification**: 'lyon', 'france', 'photo' n'aident pas √† diff√©rencier les zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2799c345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyser top tags AVANT filtrage\n",
    "all_tags_before = ' '.join(df_text_ready['tags_clean'].dropna()).split()\n",
    "from collections import Counter\n",
    "top_before = Counter(all_tags_before).most_common(20)\n",
    "\n",
    "print(\"Top 20 tags AVANT filtrage:\")\n",
    "for i, (tag, count) in enumerate(top_before, 1):\n",
    "    print(f\"{i:2}. {tag:20} : {count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36703d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer stop-tags\n",
    "df_filtered_tags = filter_stop_tags(\n",
    "    df_text_ready.copy(),\n",
    "    stop_tags=['lyon', 'france', 'photo', 'photos', 'flickr', 'city', 'ville']\n",
    ")\n",
    "\n",
    "# Top tags APR√àS\n",
    "all_tags_after = ' '.join(df_filtered_tags['tags_clean'].dropna()).split()\n",
    "top_after = Counter(all_tags_after).most_common(20)\n",
    "\n",
    "print(\"\\nTop 20 tags APR√àS filtrage:\")\n",
    "for i, (tag, count) in enumerate(top_after, 1):\n",
    "    print(f\"{i:2}. {tag:20} : {count:,}\")\n",
    "\n",
    "print(\"\\n‚úÖ Tags plus discriminants ‚Üí meilleur TF-IDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e148e8",
   "metadata": {},
   "source": [
    "## 5. NIVEAU 2 - Gestion utilisateurs hyper-actifs\n",
    "\n",
    "**Cas d'usage**: √âviter biais densit√© (1 user = 5000 photos m√™me lieu)\n",
    "\n",
    "**Justification**: Repr√©sentativit√© vs sur-repr√©sentation individuelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544987fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyser distribution users\n",
    "user_dist = df_text_ready['user_id'].value_counts()\n",
    "\n",
    "print(\"Distribution photos/user:\")\n",
    "print(f\"  Min: {user_dist.min()}\")\n",
    "print(f\"  M√©diane: {user_dist.median():.0f}\")\n",
    "print(f\"  Moyenne: {user_dist.mean():.1f}\")\n",
    "print(f\"  Max: {user_dist.max()}\")\n",
    "print(f\"  P90: {user_dist.quantile(0.9):.0f}\")\n",
    "print(f\"  P95: {user_dist.quantile(0.95):.0f}\")\n",
    "print(f\"  P99: {user_dist.quantile(0.99):.0f}\")\n",
    "\n",
    "# Identifier heavy users\n",
    "heavy_threshold = 500\n",
    "heavy = user_dist[user_dist > heavy_threshold]\n",
    "print(f\"\\n{len(heavy)} utilisateurs avec > {heavy_threshold} photos\")\n",
    "print(f\"Repr√©sentent {heavy.sum():,} photos ({heavy.sum()/len(df_text_ready)*100:.1f}% du dataset)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b0568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limiter heavy users\n",
    "df_balanced = filter_by_user_density(\n",
    "    df_text_ready.copy(),\n",
    "    max_photos_per_user=500,\n",
    "    strategy='sample'  # ou 'limit'\n",
    ")\n",
    "\n",
    "print(f\"\\n‚öñÔ∏è  Dataset r√©√©quilibr√©:\")\n",
    "print(f\"  Avant: {len(df_text_ready):,}\")\n",
    "print(f\"  Apr√®s: {len(df_balanced):,}\")\n",
    "print(f\"  Perte: {len(df_text_ready) - len(df_balanced):,}\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  √Ä documenter: impact sur repr√©sentativit√© spatiale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3de2a9f",
   "metadata": {},
   "source": [
    "## 6. NIVEAU 2 - Densit√© spatiale (flag isol√©s)\n",
    "\n",
    "**Cas d'usage**: Identifier photos isol√©es vs en cluster\n",
    "\n",
    "**Important**: Ne supprime PAS, juste flagge pour analyse diff√©renci√©e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c8fb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installer sklearn si besoin\n",
    "try:\n",
    "    import sklearn\n",
    "    print(\"‚úì sklearn disponible\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è  sklearn non install√©, skipper cette section\")\n",
    "    print(\"   Installation: pip install scikit-learn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d940440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter flag densit√©\n",
    "df_with_density = add_spatial_density_flag(\n",
    "    df_balanced.copy(),\n",
    "    eps_km=0.5,  # 500m\n",
    "    min_samples=5\n",
    ")\n",
    "\n",
    "# Analyser\n",
    "dense_count = df_with_density['is_dense'].sum()\n",
    "isolated_count = (~df_with_density['is_dense']).sum()\n",
    "\n",
    "print(f\"\\nR√©sultat:\")\n",
    "print(f\"  Photos denses (en cluster): {dense_count:,} ({dense_count/len(df_with_density)*100:.1f}%)\")\n",
    "print(f\"  Photos isol√©es (noise): {isolated_count:,} ({isolated_count/len(df_with_density)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nüí° Usage:\")\n",
    "print(\"  - Garder tout pour analyse globale\")\n",
    "print(\"  - Filtrer isol√©es pour focus sur POI majeurs\")\n",
    "print(\"  - Analyser isol√©es s√©par√©ment (√©v√©nements ponctuels?)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f504da",
   "metadata": {},
   "source": [
    "## 7. Synth√®se - Choix m√©thodologiques\n",
    "\n",
    "### Tableau r√©capitulatif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d74767f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er tableau synth√®se\n",
    "synthese = pd.DataFrame([\n",
    "    {\n",
    "        'Version': 'Baseline (conservatif)',\n",
    "        'Photos': len(df_clean),\n",
    "        'GPS': (~df_clean[['lat','lon']].isna().any(axis=1)).sum(),\n",
    "        'Dates': df_clean['has_valid_date'].sum(),\n",
    "        'Texte': (df_clean['text_merged'] != '').sum(),\n",
    "        'Usage': 'Clustering spatial',\n",
    "    },\n",
    "    {\n",
    "        'Version': '+ Filtre texte',\n",
    "        'Photos': len(df_text_ready),\n",
    "        'GPS': (~df_text_ready[['lat','lon']].isna().any(axis=1)).sum(),\n",
    "        'Dates': df_text_ready['has_valid_date'].sum(),\n",
    "        'Texte': (df_text_ready['text_merged'] != '').sum(),\n",
    "        'Usage': 'Description zones',\n",
    "    },\n",
    "    {\n",
    "        'Version': '+ Stop-tags',\n",
    "        'Photos': len(df_filtered_tags),\n",
    "        'GPS': (~df_filtered_tags[['lat','lon']].isna().any(axis=1)).sum(),\n",
    "        'Dates': df_filtered_tags['has_valid_date'].sum(),\n",
    "        'Texte': (df_filtered_tags['text_merged'] != '').sum(),\n",
    "        'Usage': 'TF-IDF optimis√©',\n",
    "    },\n",
    "    {\n",
    "        'Version': '+ √âquilibrage users',\n",
    "        'Photos': len(df_balanced),\n",
    "        'GPS': (~df_balanced[['lat','lon']].isna().any(axis=1)).sum(),\n",
    "        'Dates': df_balanced['has_valid_date'].sum(),\n",
    "        'Texte': (df_balanced['text_merged'] != '').sum(),\n",
    "        'Usage': 'Densit√© non-biais√©e',\n",
    "    },\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SYNTH√àSE - Versions du dataset\")\n",
    "print(\"=\"*80)\n",
    "print(synthese.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RECOMMANDATION\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "1. Clustering spatial (KMeans/DBSCAN/Hierarchical):\n",
    "   ‚Üí Utiliser BASELINE (conservatif, max donn√©es)\n",
    "\n",
    "2. Text mining (TF-IDF, association rules):\n",
    "   ‚Üí Utiliser + Stop-tags (tags discriminants)\n",
    "\n",
    "3. Analyse temporelle:\n",
    "   ‚Üí Utiliser BASELINE + filtrer sur 'has_valid_date'\n",
    "\n",
    "4. Validation milestones:\n",
    "   ‚Üí Tester AVEC et SANS filtres avanc√©s\n",
    "   ‚Üí Documenter impact sur r√©sultats\n",
    "   ‚Üí Justifier choix selon objectif\n",
    "\n",
    "‚úÖ Approche d√©fendable √† l'oral:\n",
    "   \"Nettoyage conservatif + filtres optionnels document√©s\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05854d67",
   "metadata": {},
   "source": [
    "## 8. Export des versions\n",
    "\n",
    "Sauvegarder les diff√©rentes versions pour analyse ult√©rieure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2048b53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er r√©pertoire versions\n",
    "versions_dir = Path('../data/versions')\n",
    "versions_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Sauvegarder (optionnel)\n",
    "# df_clean.to_parquet(versions_dir / 'baseline.parquet')\n",
    "# df_text_ready.to_parquet(versions_dir / 'text_ready.parquet')\n",
    "# df_filtered_tags.to_parquet(versions_dir / 'filtered_tags.parquet')\n",
    "# df_balanced.to_parquet(versions_dir / 'balanced.parquet')\n",
    "\n",
    "print(\"‚úì Versions pr√™tes pour analyse\")\n",
    "print(f\"  Baseline: {len(df_clean):,} photos\")\n",
    "print(f\"  Text-ready: {len(df_text_ready):,} photos\")\n",
    "print(f\"  Filtered-tags: {len(df_filtered_tags):,} photos\")\n",
    "print(f\"  Balanced: {len(df_balanced):,} photos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df21f33",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "### Ce notebook d√©montre:\n",
    "\n",
    "1. ‚úÖ **Cleaning conservatif de base** = optimal pour projet acad√©mique\n",
    "2. ‚úÖ **Filtres optionnels** = adaptables selon objectif analyse\n",
    "3. ‚úÖ **Tra√ßabilit√© compl√®te** = justification m√©thodologique\n",
    "4. ‚úÖ **Flexibilit√©** = tester plusieurs approches\n",
    "\n",
    "### Pour les milestones suivants:\n",
    "\n",
    "- **Milestone 1** (Exploration): Utiliser baseline + visualisations\n",
    "- **Milestone 2** (Clustering): Tester baseline vs balanced\n",
    "- **Milestone 3** (Text mining): Utiliser filtered_tags\n",
    "- **Milestone 4** (Temporel): Filtrer sur has_valid_date\n",
    "\n",
    "### R√©ponse jury:\n",
    "\n",
    "> *\"Peut-on nettoyer davantage?\"*\n",
    "\n",
    "**‚Üí** Oui, mais nous avons volontairement choisi un cleaning conservatif pour ne pas perdre d'information utile. Des nettoyages plus agressifs (filtrage s√©mantique, pond√©ration utilisateurs, filtrage par densit√©) ont √©t√© identifi√©s comme pistes d'am√©lioration et peuvent √™tre activ√©s selon l'objectif (zones touristiques vs √©v√©nements)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
